# MCP系统待开发功能点集合

本文档用于记录MCP系统开发过程中产生的功能点灵感和改进建议，作为未来开发规划的参考。

## 文档使用指南

1. **添加新功能点**：按照模板格式添加新的功能点
2. **优先级标记**：使用标签[高/中/低]标记功能优先级
3. **状态跟踪**：使用状态标签[待评估/已规划/开发中/已完成/已放弃]
4. **定期评审**：团队定期评审文档，更新优先级和状态

---

## 功能点列表

### 1. MCP服务智能路由 [优先级:中] [状态:待评估]

#### 背景

当前MCP客户端启动时需要手动指定特定的MCP服务器（如web3-rpc、playwright等），这对用户不友好，因为：

1. 用户必须预先知道具体的MCP服务器名称
2. 用户需要手动指定服务器，增加使用复杂度
3. 对新用户存在较高的学习成本
4. 不同功能分散在不同服务器，需要频繁切换

#### 功能描述

设计并实现一个智能路由层，能够根据用户的自然语言指令自动选择合适的MCP服务器，无需用户手动指定。

```
用户查询 -> 智能路由层 -> 合适的MCP服务器
```

#### 主要特性

1. **自动服务识别**
   - 分析用户的自然语言指令
   - 通过关键词匹配、意图识别等方式确定所需服务
   - 自动将请求路由到对应的MCP服务器

2. **服务注册机制**
   - 每个MCP服务器注册其支持的功能和关键词
   - 建立功能-服务器映射关系
   - 支持动态服务发现和注册

3. **多服务器协同**
   - 支持一个查询同时调用多个服务器
   - 服务器之间可以协同工作
   - 结果自动整合返回给用户

4. **平滑切换**
   - 在用户会话过程中根据需求自动切换服务器
   - 保持会话连续性，无需用户感知服务器切换

#### 技术方案

##### 1. 服务注册表设计

```json
{
  "services": {
    "web3-rpc": {
      "keywords": ["solana", "ethereum", "blockchain", "钱包", "代币", "转账"],
      "tools": ["getBalance", "transfer", "swap", "getAccountInfo"],
      "description": "区块链相关服务"
    },
    "playwright": {
      "keywords": ["browser", "web", "浏览器", "网页", "点击", "导航"],
      "tools": ["navigate", "click", "type", "screenshot"],
      "description": "Web浏览和自动化功能"
    },
    "amap-maps": {
      "keywords": ["地图", "位置", "导航", "距离", "路线"],
      "tools": ["locate", "route", "search"],
      "description": "高德地图服务和位置信息"
    }
  }
}
```

##### 2. 路由算法

1. 关键词匹配：从用户输入中提取关键词，与服务关键词列表匹配
2. 工具名称识别：识别用户是否直接提及特定工具名称
3. 历史上下文：考虑用户会话历史，保持服务连续性
4. 兜底策略：当无法确定时，使用默认服务或向用户确认

##### 3. 实现架构

```python
class MCPRouter:
    def __init__(self):
        self.services = self._load_services()
        self.service_cache = {}  # 缓存用户会话使用的服务
    
    def _load_services(self):
        # 从配置文件加载服务信息
        # 返回服务配置字典
        pass
    
    def route_query(self, user_id, query):
        # 分析用户查询
        relevant_services = self.identify_relevant_services(query)
        
        # 选择最合适的服务
        selected_service = self.select_best_service(
            user_id, 
            relevant_services, 
            query
        )
        
        # 更新缓存
        self.service_cache[user_id] = selected_service
        
        # 返回选择的服务
        return selected_service
    
    def identify_relevant_services(self, query):
        # 实现关键词匹配等逻辑
        # 返回相关服务列表及相关度分数
        pass
    
    def select_best_service(self, user_id, relevant_services, query):
        # 考虑各种因素选择最佳服务
        # 包括历史上下文、相关度分数等
        pass
```

#### 开发计划

##### 阶段一：基础功能实现

1. 设计并实现服务注册表数据结构
2. 实现基本关键词匹配路由算法
3. 集成到MCP客户端启动流程
4. 添加测试用例和基准测试

##### 阶段二：增强功能

1. 增加自然语言处理能力，提高意图识别准确率
2. 实现多服务器协同调用机制
3. 添加用户反馈学习机制，优化路由决策
4. 实现服务自动发现和动态注册

##### 阶段三：优化和扩展

1. 性能优化，减少路由决策时间
2. 添加服务健康检查和失败转移
3. 支持用户自定义服务映射规则
4. 开放API，支持第三方服务集成

#### 风险与挑战

1. 关键词匹配可能不足以准确识别复杂任务
2. 多服务协同可能引入新的复杂度和潜在问题
3. 用户查询表述不清晰时的决策策略
4. 服务动态变化时的适应性

#### 评估指标

1. 服务选择准确率：>95%
2. 路由决策耗时：<100ms
3. 用户满意度调查：>4.5/5分
4. 多服务协同成功率：>90%

---

### 2. 功能点模板 [优先级:] [状态:待评估]

#### 背景

描述当前系统存在的问题或需要改进的地方。

#### 功能描述

概述这个功能点的核心内容和价值。

#### 主要特性

列出这个功能点的主要特性。

#### 技术方案

提供初步的技术方案和实现思路。

#### 开发计划

描述可能的开发阶段和任务。

#### 风险与挑战

列出可能的技术挑战和风险点。

#### 评估指标

定义成功实现的评估标准。

---

### 3. 增强 API 安全性 (HTTPS & 认证) [优先级:高] [状态:待评估]

#### 背景

当前本地开发环境使用 HTTP，且未强制执行身份认证，这在正式部署环境中存在严重安全风险，如数据窃听、篡改、未授权访问等。

#### 功能描述

确保所有面向公网的 API 接口都强制使用 HTTPS 加密传输，并实施严格的身份认证机制，保护用户数据和系统资源。

#### 主要特性

1.  **HTTPS 强制**：所有 API 请求必须通过 HTTPS 访问。
2.  **身份认证**：所有需要保护的 API（如 `/execute`, `/intent/process` 等）必须校验有效的用户身份凭证（如 JWT Token）。
3.  **认证中间件**：实现 FastAPI 中间件来处理 Token 的验证和用户身份的解析。

#### 技术方案

1.  **HTTPS**：在服务器（如 Nginx 反向代理）上配置 SSL/TLS 证书。推荐使用 Certbot + Let's Encrypt 实现证书的自动获取和续订。
2.  **身份认证**：
    *   实现用户登录接口（如果尚未实现）以颁发 JWT Token。
    *   实现 FastAPI 依赖项或中间件，用于验证请求头中的 `Authorization: Bearer <token>`，解析用户信息。
    *   使用 `python-jose` 或类似库处理 JWT。

#### 开发计划

1.  **部署阶段**：在首次部署到生产或预生产环境前必须完成。
2.  **后端开发**：实现认证中间件和依赖项。
3.  **前端配合**：前端需实现登录逻辑，并在调用 API 时携带 Token。

#### 风险与挑战

1.  证书配置和自动续订的正确性。
2.  JWT 密钥的安全管理。
3.  前端 Token 存储的安全性（如使用 HttpOnly Cookie 或 LocalStorage/SessionStorage 的权衡）。

#### 评估指标

1.  所有公网 API 均强制 HTTPS。
2.  受保护的 API 在缺少或无效 Token 时返回 401/403 错误。
3.  成功认证后，后端能正确识别用户身份。

---

### 4. 实现 API 速率限制 [优先级:高] [状态:待评估]

#### 背景

未加限制的 API 可能被恶意用户或程序滥用，通过大量请求耗尽服务器资源、增加外部 API 调用成本（LLM, Coze/Dify 等）或导致拒绝服务。

#### 功能描述

对核心 API 接口（特别是 `/intent/process` 和 `/execute`）实施速率限制，限制单个用户或 IP 在单位时间内的请求次数。

#### 主要特性

1.  **基于标识的限制**：可以基于用户 ID、IP 地址或 API Key（如果未来提供给开发者）进行限制。
2.  **可配置阈值**：限制的频率（如 60次/分钟）和时间窗口应该是可配置的。
3.  **清晰的错误响应**：当达到限制时，返回明确的 429 Too Many Requests 错误。

#### 技术方案

1.  **应用层实现**：使用 Python 库如 `slowapi`，它可以与 FastAPI 很好地集成，并支持基于内存、Redis 等多种存储后端来跟踪请求计数。
2.  **网关/代理层实现**：在反向代理服务器（如 Nginx）层面配置速率限制模块（如 `ngx_http_limit_req_module`）。
3.  **混合方案**：可能同时使用两者，例如 Nginx 做初步的 IP 级限制，应用层做更细粒度的用户级限制。

#### 开发计划

1.  **评估**：确定限制策略（基于什么标识？限制多少？）。
2.  **实现**：选择技术方案并集成到后端。
3.  **测试**：验证限制是否生效，以及错误响应是否正确。
4.  **部署前完成**：应在正式上线前部署此功能。

#### 风险与挑战

1.  限制策略过于严格可能影响正常用户体验。
2.  分布式部署时，需要在多个实例间共享计数状态（如使用 Redis）。
3.  如何区分正常的高频使用和恶意攻击。

#### 评估指标

1.  超过限制阈值的请求被正确拒绝，并返回 429 状态码。
2.  正常频率的请求不受影响。
3.  限制计数器能正确工作（例如，在时间窗口后重置）。

---

### 5. 强化工具（API）接入流程的安全性 [优先级:高] [状态:待评估]

#### 背景

系统允许外部开发者接入其工具（如 Coze/Dify 应用或其他 HTTP API）。直接信任和使用开发者提交的配置信息（如 API Key, Schema, 描述）存在安全风险，可能导致数据泄露、系统被利用或崩溃。

#### 功能描述

建立一套安全的工具接入流程，对开发者提交的信息进行严格的验证、清理和安全存储，并考虑引入审核机制。

#### 主要特性

1.  **严格的输入验证**：在将工具信息存入数据库前，对所有字段进行格式、类型、长度、字符集和内容的验证（特别是 JSON Schema 和 Endpoint 配置的有效性）。
2.  **内容清理 (Sanitization)**：对可能在前端展示的字段（如 name, description）进行 XSS 清理。
3.  **API Key 安全存储**：不将 API Key 明文存储在数据库。使用密钥管理服务（如 Vault）或至少进行加密存储。
4.  **工具审核流程 (可选)**：新提交或修改的工具需要经过管理员审核才能生效。

#### 技术方案

1.  **输入验证**：
    *   后端使用 Pydantic 或手动编写验证逻辑。
    *   使用 `jsonschema` 库验证 `request_schema` 和 `response_schema`。
    *   对 `endpoint` JSON 根据 `platform` 进行特定字段的验证。
2.  **内容清理**：使用如 `bleach` 的 Python 库。
3.  **API Key 存储**：
    *   **方案一 (推荐)**：集成 Vault 或云服务商的 Secrets Manager。
    *   **方案二 (次选)**：使用 `cryptography` 库对 API Key 进行对称或非对称加密后再存储，密钥本身需要安全管理。
4.  **审核流程**：在 `tools` 表中添加 `status` 字段（如 `pending_review`, `approved`, `rejected`），并开发简单的管理界面或脚本。

#### 开发计划

1.  **基础验证**：在 MVP 阶段或首次允许外部接入前，实现基础的输入验证（JSON 格式、必需字段）。
2.  **安全存储与审核**：在正式开放开发者接入前，完成 API Key 安全存储和审核流程的设计与实现。

#### 风险与挑战

1.  验证逻辑可能不全面，被绕过。
2.  密钥管理系统本身的复杂性和安全性。
3.  审核流程可能带来效率问题。

#### 评估指标

1.  格式错误或缺少必要信息的工具提交被拒绝。
2.  API Key 在数据库中非明文存储。
3.  通过验证的 Schema 是有效的 JSON Schema。
4.  (如果实现) 未经审核的工具无法被系统调用。

---

### 6. MCP 工具信息自动同步 [优先级:高] [状态:待评估]

#### 背景

当前系统设计依赖 `tools` 数据库表作为所有可用工具（包括 MCP 工具）的注册中心，LLM 需要查询此表来理解工具能力和参数。但 MCP 服务器及其提供的工具可能会更新，手动维护 `tools` 表中 MCP 工具的信息不现实、易出错且效率低下。

#### 功能描述

设计并实现一种机制，能够自动将已配置的 MCP 服务器所提供的工具列表及其元数据（名称、描述、请求/响应 Schema）同步到后端的 `tools` 数据库表中，确保数据库信息与 MCP 服务器的实际能力保持一致。

#### 主要特性

1.  **自动发现/读取**：能够从 MCP 服务器（或其中心化配置）获取其提供的工具列表和详细元数据。
2.  **数据库同步**：将获取到的 MCP 工具信息自动创建或更新到 `tools` 表中。
3.  **差异处理**：能够处理工具的增、删、改情况。
4.  **调度机制**：可以配置同步的时机（如服务启动时、定期、手动触发）。

#### 技术方案

*   **方案一：MCP 服务器提供元数据接口**：修改 MCP 服务器，实现 `/tools_metadata` 接口。后端服务启动或定期调用此接口获取信息并同步。
*   **方案二：通过 MCP 客户端发现**：修改 MCP 协议和客户端，增加列出/查询工具元数据的功能。后端连接服务器后主动查询并同步。
*   **方案三：中心化配置 + 同步脚本 (推荐)**：扩展现有的 MCP 服务器配置文件（或使用独立文件），详细列出每个服务器的工具及其元数据。创建一个同步脚本，读取此配置并更新数据库。该脚本可在服务启动时运行或手动/定期运行。

#### 开发计划

1.  **方案选型**：评估三种方案的可行性、成本和维护性，确定最终方案。
2.  **设计**：根据选定方案，设计配置文件格式（方案三）或接口规范（方案一/二），以及数据库同步逻辑（如何处理增删改）。
3.  **实现**：编写同步脚本或实现相关的接口/客户端功能。
4.  **集成**：将同步机制集成到服务启动流程或调度系统中。
5.  **测试**：验证同步的准确性和完整性。

#### 风险与挑战

1.  方案一/二需要修改 MCP 服务器/协议，涉及多方协调。
2.  方案三依赖配置文件的手动维护和准确性。
3.  如何高效地处理大量工具的同步。
4.  同步过程中发生错误的回滚或重试机制。

#### 评估指标

1.  `tools` 表中的 MCP 工具信息与实际服务器（或配置文件）保持一致。
2.  同步过程稳定可靠，错误可追踪。
3.  同步所需时间在可接受范围内。

---

### 7. LLM Prompt 数据库化管理 [优先级:中] [状态:待评估]

#### 背景

当前系统的 LLM Prompt（如意图理解指令、工具描述格式、结果总结指令）硬编码在代码中，不便于维护、迭代和非技术人员调整。

#### 功能描述

将所有 LLM Prompt 模板从代码中分离出来，存入数据库（如 `prompts` 表），允许通过数据库或管理后台动态修改和管理 Prompt。

#### 主要特性

1.  **Prompt 模板化存储**：支持存储包含占位符的 Prompt 模板。
2.  **版本控制 (可选)**：支持记录 Prompt 的不同版本。
3.  **多语言支持 (可选)**：支持存储不同语言的 Prompt 模板。
4.  **便捷更新**：修改 Prompt 无需重新部署后端代码。

#### 技术方案

1.  创建 `prompts` 数据库表 (`prompt_key`, `prompt_template`, `language`, `version`, etc.)。
2.  后端服务在需要时根据 `prompt_key` 和 `language` 从数据库加载模板。
3.  使用加载的模板和运行时数据（如用户查询、工具结果）填充占位符，生成最终 Prompt。

#### 开发计划

1.  设计数据库表结构。
2.  实现后端加载和填充 Prompt 的逻辑。
3.  (可选) 开发简单的 Prompt 管理界面。

#### 风险与挑战

1.  数据库查询可能引入微小延迟。
2.  需要设计好 `prompt_key` 的命名规范。
3.  Prompt 模板语法的标准化。

#### 评估指标

1.  Prompt 可通过数据库进行修改。
2.  后端能正确加载、填充并使用数据库中的 Prompt。

---

### 8. 灵活的应用配置管理机制 [优先级:低] [状态:待评估]

#### 背景

除了敏感和环境相关的配置（适合环境变量），部分应用级配置（如可选 LLM 模型列表、功能开关、某些默认参数）可能需要更灵活的管理方式，便于运营或产品调整。

#### 功能描述

评估并引入一种机制（如数据库配置表或配置中心服务），用于管理非敏感、需要动态调整的应用级配置，补充环境变量管理方式。

#### 主要特性

1.  **集中管理**：将可调整的应用配置集中存放。
2.  **动态生效 (可选)**：部分配置的修改可以无需重启服务即生效。
3.  **易于访问**：提供接口或机制供后端服务读取这些配置。

#### 技术方案

1.  **数据库配置表**：创建一个 `app_configs` 表 (`config_key`, `config_value`, `description`)。
2.  **配置中心**：集成开源（如 Apollo, Nacos）或商业配置中心服务。
3.  **混合方案**：结合环境变量和数据库/配置中心。

#### 开发计划

1.  **需求分析**：明确哪些配置适合放入此机制管理。
2.  **技术选型**：选择数据库表方案还是配置中心方案。
3.  **实现**：实现配置的读取和（可能的）动态更新逻辑。

#### 风险与挑战

1.  引入配置中心会增加系统复杂度。
2.  数据库配置方案需要处理好缓存和更新机制。
3.  明确哪些配置适合动态调整，哪些需要重启。

#### 评估指标

1.  选定的应用配置可通过新机制进行管理。
2.  后端服务能正确读取和使用这些配置。

---

### 9. 多语言支持 [优先级:中] [状态:待评估]

#### 背景

当前系统仅支持单一语言（如中文）交互，限制了用户范围。

#### 功能描述

实现对多种语言的支持，允许用户使用其偏好的语言与系统交互，系统也能以该语言进行响应和播报。

#### 主要特性

1.  **语言参数传递**：前后端接口增加 `language` 参数。
2.  **LLM 多语言指令**：在调用 LLM 时明确指示其使用目标语言。
3.  **多语言 Prompt (依赖 T007)**：如果 Prompt 数据库化，需要支持多语言模板。
4.  **外部工具适配 (可选)**：如果调用的工具支持多语言，传递语言参数。
5.  **TTS 引擎支持**：确保 TTS 引擎支持所需语言。

#### 技术方案

1.  前端获取用户语言偏好（浏览器设置或选择菜单）。
2.  修改 API 请求和响应 Schema，增加 `language` 字段。
3.  修改后端调用 LLM 的逻辑，在 Prompt 中加入语言指令。
4.  (如果实现 Prompt 数据库化) 扩展 `prompts` 表支持 `language`。
5.  评估并配置 TTS 服务以支持多语言。

#### 开发计划

1.  确定需要支持的语言列表。
2.  完成前后端接口改造。
3.  调整 LLM 调用逻辑和 Prompt。
4.  配置和测试 TTS。
5.  进行全面的多语言测试。

#### 风险与挑战

1.  LLM 对某些语言或特定任务的处理效果可能不同。
2.  维护多语言 Prompt 的工作量。
3.  外部工具的多语言支持情况不一。
4.  TTS 引擎对不同语言的发音质量。

#### 评估指标

1.  用户可以使用指定的语言进行交互。
2.  系统的响应和播报使用对应的语言。
3.  核心功能在支持的语言下均可正常工作。

---

### 10. 前端展示结构化工具结果 [优先级:低] [状态:待评估]

#### 背景

当前 MVP 方案中，后端 `/execute` 接口只返回适合 TTS 播报的纯文本 `result.message`。对于某些工具（如天气、搜索结果），如果能在前端 UI 上展示更丰富、结构化的信息（如天气卡片、结果列表），用户体验会更好。

#### 功能描述

在后端 `/execute` 接口的响应中增加一个字段（如 `result.data` 或 `result.structured_data`），用于传递工具返回的原始或经过标准化的结构化数据。前端根据这些数据，可以渲染出更丰富的界面元素。

#### 主要特性

1.  **后端传递结构化数据**：`/execute` 响应增加 `result.data` 字段。
2.  **数据标准化 (可选)**：后端尝试将常见的工具结果标准化为预定义的几种 Schema。
3.  **前端动态渲染**：前端根据 `result.data` 的类型或元数据，选择合适的组件进行渲染。

#### 技术方案

1.  **后端修改**：
    *   修改 `ExecuteResponse` Schema，添加 `data: Optional[Any]` 字段。
    *   `ExecuteService` 在处理工具结果时，除了生成 `message`，还将原始或标准化后的结构化数据放入 `data`。
    *   (可选) 在响应中增加 `dataType` 字段提示前端数据类型。
2.  **前端开发**：
    *   开发用于展示不同类型数据的 React 组件（如 WeatherCard, SearchResultList, GenericJsonViewer）。
    *   前端根据响应中的 `dataType` 或 `data` 的结构，动态选择并渲染对应组件。

#### 开发计划

1.  **确定需要优先支持结构化展示的工具类型**。
2.  **后端实现**：标准化数据（如果采用）并修改 API 响应。
3.  **前端实现**：开发对应的展示组件和动态加载逻辑。

#### 风险与挑战

1.  工具返回的数据结构多样，完全标准化难度大。
2.  前端需要开发和维护多个展示组件。
3.  如何在有限的界面空间内优雅地展示复杂数据。

#### 评估指标

1.  对于支持的工具类型，前端能展示结构化的信息界面。
2.  对于不支持的类型，能有合理的降级处理（如只播报 message 或显示通用 JSON）。

---

### 11. 强化FastAPI响应序列化与命名规范 [优先级:高] [状态:待评估]

#### 背景

在API开发过程中，我们遇到了Pydantic模型字段别名(`alias`)在FastAPI响应序列化时不生效的问题。这导致前端接收到的JSON字段名与预期不符，造成数据获取困难。特别是当前后端分离开发中，这类问题容易导致长时间的排障和联调成本。

#### 功能描述

建立统一的FastAPI响应序列化规范，确保API响应字段的命名一致性，并预防因Pydantic模型配置不完整导致的序列化问题。

#### 主要特性

1. **标准化响应模型配置**：为所有响应模型提供标准的`Config`类配置，确保`alias`正确应用于JSON输出。
2. **命名规范统一**：制定并实施API字段命名规范（如前端使用camelCase，后端使用snake_case，通过alias自动转换）。
3. **基础响应模型**：创建包含标准配置的基础响应模型类，供其他模型继承。
4. **序列化验证测试**：开发自动化测试，验证所有API响应的字段命名符合规范。

#### 技术方案

1. **创建基础响应模型**：
```python
class APIModel(BaseModel):
    """所有API响应模型的基类，包含标准序列化配置"""
    
    class Config:
        populate_by_name = True
        allow_population_by_field_name = True
        alias_priority = 2  # 确保别名优先
        extra = "ignore"
```

2. **实施命名规范转换**：
```python
def to_camel(snake_str: str) -> str:
    """将snake_case转换为camelCase"""
    components = snake_str.split('_')
    return components[0] + ''.join(x.title() for x in components[1:])

class CamelModel(APIModel):
    """自动将snake_case字段名转换为camelCase的模型基类"""
    
    class Config:
        alias_generator = to_camel
```

3. **建立响应模型检查机制**：
   - 开发Pytest测试，验证所有API是否正确序列化字段名
   - 考虑实现自定义linter规则，确保所有响应模型继承自基础模型

#### 开发计划

1. **阶段一：基础实现**
   - 创建基础响应模型类
   - 修改现有响应模型继承基础类
   - 编写测试验证序列化行为

2. **阶段二：规范与文档**
   - 制定详细的API命名规范文档
   - 为团队进行培训，确保理解规范
   - 实现命名检查工具

3. **阶段三：自动化与监控**
   - 在CI/CD管道中添加响应格式验证
   - 实现运行时响应格式监控

#### 风险与挑战

1. 现有代码库可能需要大量修改
2. 命名规范的改变可能影响前端代码
3. 自动生成的文档与实际响应可能存在不一致

#### 评估指标

1. 所有API响应的字段命名符合规定的规范
2. 消除由字段命名不一致导致的前后端联调问题
3. 开发者能正确应用命名规范和序列化配置

## 历史记录

| 日期 | 功能点 | 变更内容 | 变更人 |
|------|--------|----------|--------|
| 2025-04-16 | MCP服务智能路由 | 初始创建 | AI助手 |
| 2025-04-29 | 强化FastAPI响应序列化与命名规范 | 初始创建 | AI助手 |

## 贡献指南

1. **添加新功能点**：按照上述模板格式添加新的功能点
2. **完善已有功能点**：随时更新和完善已有功能点的详细信息
3. **优先级评估**：每次团队会议评估功能点优先级
4. **状态更新**：负责人定期更新功能点开发状态 